# main.py
# (V47.0 - Fully Asynchronous & CORRECTED Non-Blocking Startup)
# --- Project Nexus AI Assistant Server ---

import uvicorn
from fastapi import FastAPI, HTTPException, BackgroundTasks, WebSocket, WebSocketDisconnect
from fastapi.responses import FileResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
import os
import traceback
from contextlib import asynccontextmanager
from sentence_transformers import SentenceTransformer, CrossEncoder
import torch
import time
import asyncio # <-- [V30] (‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á)
from datetime import datetime, timedelta

# --- ‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á Core (V25-V47 Fix) ---
from core.config import settings
from core.dispatcher import Dispatcher, FinalResponse
from core.rag_engine import RAGEngine # (V32)
from core.memory_manager import MemoryManager # (V17)
from core.long_term_memory_manager import LongTermMemoryManager # (V34)
from core.api_key_manager import ApiKeyManager # (V25)
from core.graph_manager import GraphManager # (V2.1 - Sync OK!)
from core.groq_key_manager import GroqApiKeyManager # (V25)
from core.tts_engine import TextToSpeechEngine # (V33)
# --- ‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á Agents (V11-V46) ---
from agents.planning_mode.planner_agent import PlannerAgent # (V9)
from agents.formatter_agent import FormatterAgent # (V10)
from agents.consultant_mode.librarian_agent import LibrarianAgent # (V43)
from agents.coder_mode.code_interpreter_agent import CodeInterpreterAgent # (V45)
from agents.utility_mode.reporter_agent import ReporterAgent
from agents.utility_mode.system_agent import SystemAgent # (V22)
from agents.utility_mode.image_agent import ImageAgent # (V36)
from agents.news_mode.news_agent import NewsAgent # (V11)
from agents.feng_mode.feng_agent import FengAgent # (V37)
from agents.counseling_mode.counselor_agent import CounselorAgent # (V14)
from agents.storytelling_mode.listener_agent import ListenerAgent # (V38)
from agents.apology_agent.apology_agent import ApologyAgent # (V46)
from agents.feng_mode.general_conversation_agent import GeneralConversationAgent # (V42)
from agents.feng_mode.proactive_offer_agent import ProactiveOfferAgent # (V41)
from agents.memory_mode.memory_agent import MemoryAgent # (V40)
from agents.persona_core import FENG_PERSONA_PROMPT
from agents.presenter.presenter_agent import PresenterAgent # (V39)


web_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "web")

AGENTS = {}
GRAPH_MANAGER: GraphManager = None
DISPATCHER: Dispatcher = None
audio_tasks = {}

# [V33] (‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô create_audio_file_background "‡πÅ‡∏Ç‡πá‡∏á‡πÅ‡∏£‡∏á‡∏î‡∏µ")
async def create_audio_file_background(text: str, output_path: str, task_id: str):
    """[V33] ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏£‡∏±‡∏ô‡πÉ‡∏ô Background ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á (‡πÅ‡∏ö‡∏ö Async)"""
    try:
        print(f"üéôÔ∏è  Starting background audio synthesis for task: {task_id}")
        tts_agent = AGENTS.get("TTS")
        if tts_agent:
            voice_file_path = await tts_agent.synthesize(text, output_path)
            if voice_file_path:
                audio_tasks[task_id] = {"status": "done", "url": f"/static/audio/{os.path.basename(output_path)}"}
                print(f" 	- ‚úÖ Audio task {task_id} completed.")
                return
        audio_tasks[task_id] = {"status": "failed", "error": "TTS agent not found or synthesis failed"}
    except Exception as e:
        print(f" 	- ‚ùå Background audio synthesis failed for task {task_id}: {e}")
        audio_tasks[task_id] = {"status": "failed", "error": str(e)}

# [V3.2] (‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô cleanup_old_audio_files "‡πÅ‡∏Ç‡πá‡∏á‡πÅ‡∏£‡∏á‡∏î‡∏µ")
async def cleanup_old_audio_files():
    """Service ‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏Å‡πà‡∏≤"""
    audio_dir = os.path.join(web_dir, "static", "audio")
    cleanup_interval_seconds = 300  
    max_file_age_minutes = 5 	 
    
    while True:
        await asyncio.sleep(cleanup_interval_seconds)
        
        print("üßπ Running audio cleanup service...")
        try:
            if not os.path.exists(audio_dir):
                continue

            for filename in os.listdir(audio_dir):
                if filename.endswith(".mp3"):
                    file_path = os.path.join(audio_dir, filename)
                    try:
                        file_mod_time = datetime.fromtimestamp(os.path.getmtime(file_path))
                        if datetime.now() - file_mod_time > timedelta(minutes=max_file_age_minutes):
                            print(f" 	- Deleting old audio file: {filename}")
                            os.remove(file_path)
                    except FileNotFoundError:
                        continue
        except Exception as e:
            print(f" 	- Error during audio cleanup: {e}")


# [CHANGED] "‡∏ú‡πà‡∏≤‡∏ï‡∏±‡∏î‡πÉ‡∏´‡∏ç‡πà V47.0": Non-Blocking Startup (CORRECTED)
@asynccontextmanager
async def lifespan(app: FastAPI):
    """[V47] "Lifespan" ‡∏ó‡∏µ‡πà "‡∏ú‡πà‡∏≤‡∏ï‡∏±‡∏î" ‡πÅ‡∏•‡πâ‡∏ß (Non-Blocking Startup ‡∏ó‡∏µ‡πà "‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")"""
    
    global DISPATCHER, GRAPH_MANAGER, AGENTS
    print("--- üöÄ Initializing Project Nexus Server (V47 - Async & Corrected) ---") # [CHANGED] 1. ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô
    try:
        # --- [STEP 1: ‡∏™‡∏£‡πâ‡∏≤‡∏á Key Managers (‡πÄ‡∏£‡πá‡∏ß) (V25)] ---
        google_key_manager = ApiKeyManager(all_google_keys=settings.GOOGLE_API_KEYS, silent=True)
        groq_key_manager = GroqApiKeyManager(all_groq_keys=settings.GROQ_API_KEYS, silent=True)
        
        # --- [STEP 2: ‡∏™‡∏£‡πâ‡∏≤‡∏á Models (FP16) (‡∏ä‡πâ‡∏≤... ‡πÅ‡∏ï‡πà‡πÄ‡∏î‡∏µ‡πã‡∏¢‡∏ß 'await' ‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á)] ---
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"--- üß† Initializing Central Armory on {device.upper()} (Optimized FP16 Mode) ---")
        
        def _blocking_load_hf_models():
            embedder = SentenceTransformer("intfloat/multilingual-e5-large", device=device)
            reranker = CrossEncoder("BAAI/bge-reranker-base", device=device)
            if device == "cuda":
                print(" 	- ‚ö°Ô∏è Converting models to FP16 for CUDA acceleration...")
                embedder.half()
                reranker.model.half()
            print(" 	- ‚úÖ Embedding and Reranking models (FP16) loaded.")
            return embedder, reranker
        
        hf_models_task = asyncio.create_task(asyncio.to_thread(_blocking_load_hf_models))

        # --- [STEP 3: ‡∏™‡∏£‡πâ‡∏≤‡∏á 'Core' Agents (‡πÄ‡∏£‡πá‡∏ß)] ---
        rag_engine_instance = RAGEngine(
            embedder=None, 
            reranker=None, 
        ) # (V32)
        memory_manager_instance = MemoryManager() # (V17)
        tts_engine_instance = TextToSpeechEngine() # (V33)
        ltm_manager_instance = LongTermMemoryManager( # (V34)
            embedding_model="intfloat/multilingual-e5-large",
            index_dir="data/memory_index"
        )
        
        # --- [STEP 4: ‡∏™‡∏£‡πâ‡∏≤‡∏á 'All Agents' (‡πÄ‡∏£‡πá‡∏ß)] ---
        # (‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£ 'Inject' Dependencies (V9-V47 Fixes) ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î)
        AGENTS = {
            "MEMORY": memory_manager_instance,
            "SYSTEM": SystemAgent(), # (V22)
            "REPORTER": ReporterAgent(),
            "IMAGE": ImageAgent( # (V36)
                unsplash_key=settings.UNSPLASH_ACCESS_KEY,
                key_manager=groq_key_manager,
                model_name=settings.IMAGE_AGENT_MODEL 
            ),
            "TTS": tts_engine_instance, # (V33)
            "APOLOGY": ApologyAgent( # (V46)
                key_manager=groq_key_manager,
                model_name=settings.APOLOGY_AGENT_MODEL,
                persona_prompt=FENG_PERSONA_PROMPT
            ),
            "MEMORY_QUERY": MemoryAgent( # (V40)
                key_manager=groq_key_manager, 
                model_name=settings.MEMORY_AGENT_MODEL, 
                memory_manager=memory_manager_instance, 
                persona_prompt=FENG_PERSONA_PROMPT 	
            ),
            "FENG": FengAgent( # (V37)
                key_manager=google_key_manager,
                model_name=settings.PRIMARY_GEMINI_MODEL,
                persona_prompt=FENG_PERSONA_PROMPT
            ),
            "GENERAL_HANDLER": GeneralConversationAgent( # (V42)
                key_manager=groq_key_manager,
                model_name=settings.FENG_PRIMARY_MODEL,
                rag_engine=rag_engine_instance,
                ltm_manager=ltm_manager_instance,
                persona_prompt=FENG_PERSONA_PROMPT
            ),
            "PROACTIVE_OFFER_HANDLER": ProactiveOfferAgent( # (V41)
                key_manager=groq_key_manager,
                model_name=settings.FENG_PRIMARY_MODEL,
                rag_engine=rag_engine_instance,
                persona_prompt=FENG_PERSONA_PROMPT
            ),
            "COUNSELOR": CounselorAgent( # (V14)
                key_manager=google_key_manager, 
                model_name=settings.COUNSELOR_AGENT_MODEL,
                persona_prompt=FENG_PERSONA_PROMPT
            ),
            "LISTENER": ListenerAgent( # (V38)
                key_manager=groq_key_manager,
                model_name=settings.LISTENER_AGENT_MODEL,
                persona_prompt=FENG_PERSONA_PROMPT
            ),
            "PLANNER": PlannerAgent( # (V9)
                key_manager=google_key_manager, 
                model_name=settings.PLANNER_AGENT_MODEL,
                rag_engine=rag_engine_instance,
                persona_prompt=FENG_PERSONA_PROMPT
            ),
            "CODER": CodeInterpreterAgent( # (V45)
                key_manager=groq_key_manager, 
                model_name=settings.CODE_AGENT_MODEL,
                persona_prompt=FENG_PERSONA_PROMPT
            ),
            "LIBRARIAN": LibrarianAgent( # (V43)
                key_manager=groq_key_manager, 
                model_name=settings.LIBRARIAN_AGENT_MODEL,
                rag_engine=rag_engine_instance,
                persona_prompt=FENG_PERSONA_PROMPT
            ),
            "NEWS": NewsAgent( # (V11)
                key_manager=google_key_manager, 
                model_name=settings.NEWS_AGENT_MODEL,
                rag_engine=rag_engine_instance,
                persona_prompt=FENG_PERSONA_PROMPT
            ),
            "FORMATTER": FormatterAgent( # (V10)
                key_manager=google_key_manager, 
                model_name=settings.FORMATTER_AGENT_MODEL,
                persona_prompt=FENG_PERSONA_PROMPT
            ),
            "PRESENTER": PresenterAgent( # (V39)
                key_manager=groq_key_manager,
                model_name=settings.SECONDARY_GROQ_MODEL, 
                persona_prompt=FENG_PERSONA_PROMPT
            )
        }

        # --- [STEP 5: "Await" ‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà "‡∏ä‡πâ‡∏≤" ‡πÉ‡∏´‡πâ‡πÄ‡∏™‡∏£‡πá‡∏à "‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô"] ---
        print("--- ‚è≥ Awaiting all non-blocking background loads... ---")
        
        # 5.1 "‡∏£‡∏≠" ‡πÉ‡∏´‡πâ HF Models (FP16) ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à
        embedder_instance, reranker_instance = await hf_models_task
        
        # 5.2 "Inject" Models ‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß... ‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô RAG Engine
        rag_engine_instance.embedder = embedder_instance
        rag_engine_instance.reranker = reranker_instance
        
        # 5.3 "‡∏õ‡∏•‡∏∏‡∏Å" Graph Manager (V2.1 - Sync)
        global GRAPH_MANAGER
        GRAPH_MANAGER = GraphManager() # (V2.1 init ‡πÄ‡∏£‡πá‡∏ß)
        
        # [CHANGED V47.0] "‡∏ú‡πà‡∏≤‡∏ï‡∏±‡∏î" ‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å 'gather'
        # (‡πÄ‡∏£‡∏≤ "‡πÑ‡∏°‡πà" ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å 'GRAPH_MANAGER.verify_connection_async()' (V29)
        #  ...‡πÅ‡∏ï‡πà‡πÄ‡∏£‡∏≤ "‡∏´‡πà‡∏≠" 'GRAPH_MANAGER.verify_connectivity()' (V2.1)
        #  ...‡∏î‡πâ‡∏ß‡∏¢ 'asyncio.to_thread' ‡πÅ‡∏ó‡∏ô!)
        
        # 5.4 ‡∏™‡∏£‡πâ‡∏≤‡∏á "‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡πà‡∏≠" (Wrapper) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö 'verify_connectivity' (V2.1)
        def _blocking_verify_neo4j():
            if GRAPH_MANAGER and GRAPH_MANAGER.driver:
                try:
                    print("üîó Graph Manager: Verifying Neo4j connectivity (Sync in Thread)...")
                    GRAPH_MANAGER.driver.verify_connectivity()
                    print("üîó Graph Manager: Successfully connected to Neo4j.")
                except Exception as e:
                    print(f"‚ùå Graph Manager: Could not connect to Neo4j. Error: {e}")
                    GRAPH_MANAGER.driver = None # ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
        
        # 5.5 ‡∏™‡∏±‡πà‡∏á "‡πÇ‡∏´‡∏•‡∏î" (Async) ‡∏Ñ‡∏•‡∏±‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• + "Verify" DB "‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô"
        await asyncio.gather(
            rag_engine_instance.load_models_and_index(),      # (V32 - OK)
            ltm_manager_instance.load_models_and_index(),   # (V34 - OK)
            asyncio.to_thread(_blocking_verify_neo4j)         # <-- [V47 FIX!]
        )
        
        # --- [STEP 6: ‡∏™‡∏£‡πâ‡∏≤‡∏á Dispatcher (‡πÄ‡∏£‡πá‡∏ß)] ---
        asyncio.create_task(cleanup_old_audio_files())
        DISPATCHER = Dispatcher(agents=AGENTS, key_manager=google_key_manager) # (V9)
        
        print("‚úÖ All systems operational. Hybrid AI team is ready.")
    
    except Exception as e:
        print(f"‚ùå FATAL ERROR during startup: {e}")
        traceback.print_exc()
    
    yield
    
    print("--- üåô Server shutting down ---")
    if GRAPH_MANAGER:
        GRAPH_MANAGER.close()

app = FastAPI(
    title="Project Nexus AI Assistant",
    version="V47.0-AsyncFixed", # [CHANGED] ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô!
    lifespan=lifespan
)

app.mount("/static", StaticFiles(directory=os.path.join(web_dir, "static")), name="static")

class QueryRequest(BaseModel):
    query: str
    user_id: str = "default_user"

@app.get("/", include_in_schema=False)
async def serve_frontend():
    return FileResponse(os.path.join(web_dir, 'index.html'))

@app.websocket("/ws/{user_id}")
async def websocket_endpoint(websocket: WebSocket, user_id: str):
    await websocket.accept()
    print(f"üîó WebSocket connection established for user: {user_id}")
    try:
        while True:
            query = await websocket.receive_text()
            
            async def send_update(data: dict):
                await websocket.send_json(data)

            if not DISPATCHER:
                await send_update({"type": "error", "payload": {"detail": "Server is initializing."}})
                continue
            
            try:
                await send_update({"type": "progress", "payload": {"status": "RECEIVED", "detail": "‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÅ‡∏•‡πâ‡∏ß ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•..."}})
                
                response_model = await DISPATCHER.handle_query(query, user_id, update_callback=send_update)
                
                if response_model.answer and not response_model.error:
                    timestamp = int(time.time())
                    filename = f"response_{user_id}_{timestamp}.mp3"
                    task_id = filename
                    
                    audio_dir = os.path.join(web_dir, "static", "audio")
                    os.makedirs(audio_dir, exist_ok=True)
                    output_path = os.path.join(audio_dir, filename)
                    
                    audio_tasks[task_id] = {"status": "processing"}
                    
                    asyncio.create_task(create_audio_file_background(response_model.answer, output_path, task_id)) # (V33 - OK)
                    
                    response_model.voice_task_id = task_id
                
                final_data = response_model.dict()
                await send_update({"type": "final_response", "payload": final_data})

            except Exception as e:
                print(f"‚ùå Error during WebSocket processing for user {user_id}: {e}")
                traceback.print_exc()
                await send_update({"type": "error", "payload": {"detail": "‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡πâ‡∏≤‡∏¢‡πÅ‡∏£‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•"}})

    except WebSocketDisconnect:
        print(f"üëã WebSocket connection closed for user: {user_id}")
    except Exception as e:
        print(f"‚ùå Unhandled WebSocket error for user {user_id}: {e}")
        await websocket.close(code=1011)

@app.post("/ask", response_model=FinalResponse)
async def ask_assistant(request: QueryRequest, background_tasks: BackgroundTasks):
    if not DISPATCHER:
        raise HTTPException(status_code=503, detail="Server is still initializing or has failed.")
    try:
        response = await DISPATCHER.handle_query(request.query, request.user_id)

        if response.answer and not response.error:
            timestamp = int(time.time())
            filename = f"response_{request.user_id}_{timestamp}.mp3"
            task_id = filename
            
            audio_dir = os.path.join(web_dir, "static", "audio")
            os.makedirs(audio_dir, exist_ok=True)
            output_path = os.path.join(audio_dir, filename)
            
            audio_tasks[task_id] = {"status": "processing"}
            
            # [V33 FIX] (‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á)
            asyncio.create_task(create_audio_file_background(response.answer, output_path, task_id))
            
            response.voice_task_id = task_id

        return response
        
    except Exception as e:
        print(f"‚ùå Unhandled error in /ask endpoint: {e}")
        traceback.print_exc()
        return FinalResponse(agent_used="FATAL_ERROR", answer="‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡πâ‡∏≤‡∏¢‡πÅ‡∏£‡∏á", error=True)

@app.get("/audio_status/{task_id}")
async def get_audio_status(task_id: str):
    task = audio_tasks.get(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="Task not found")
    
    if task["status"] in ["done", "failed"]:
        return audio_tasks.pop(task_id) 
        
    return task

# [CHANGED V30/V47] "‡∏ú‡πà‡∏≤‡∏ï‡∏±‡∏î" Endpoint ‡∏ô‡∏µ‡πâ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô 'async'
@app.get("/api/graph/explore", tags=["Knowledge Graph"])
async def get_graph_data_for_visualization(entity: str, limit: int = 25):
    global GRAPH_MANAGER
    if not GRAPH_MANAGER:
        raise HTTPException(status_code=503, detail="Graph Manager is not available.")
    if not entity:
        return {"nodes": [], "edges": []}
    
    # (‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô 'Blocking' ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏à‡∏∞ 'await to_thread')
    def _blocking_graph_call():
        print(f"üìà Graph Endpoint: Executing 'find_related_concepts' (Sync) in Thread...")
        try:
            # (‡πÄ‡∏£‡∏µ‡∏¢‡∏Å 'GraphManager' (V2.1) ‡∏ó‡∏µ‡πà "‡∏ö‡∏•‡πá‡∏≠‡∏Å")
            return GRAPH_MANAGER.find_related_concepts(entity, limit=limit)
        except Exception as e:
            print(f"‚ùå Graph Endpoint: Error during blocking call: {e}")
            return [{"error": str(e)}] 

    try:
        # "await" ‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô‡πÉ‡∏ô‡πÄ‡∏ò‡∏£‡∏î‡πÅ‡∏¢‡∏Å (‡πÑ‡∏°‡πà‡∏ö‡∏•‡πá‡∏≠‡∏Å)
        relations = await asyncio.to_thread(_blocking_graph_call)

        # [V34 FIX] (‡πÅ‡∏Å‡πâ‡∏ö‡∏±‡πä‡∏Å 'list' object has no attribute 'count')
        if not relations or (isinstance(relations, list) and relations and relations[0].get("error")):
            error_msg = relations[0].get("error") if relations else "Unknown error"
            raise Exception(f"Graph query failed in thread: {error_msg}")

        # (‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡∏£‡πâ‡∏≤‡∏á Nodes/Edges... "‡πÅ‡∏Ç‡πá‡∏á‡πÅ‡∏£‡∏á‡∏î‡∏µ")
        nodes, edges, node_ids = [], [], set()
        for rel in relations:
            if 'source_id' not in rel or 'target_id' not in rel: continue # [NEW] ‡∏Å‡∏±‡∏ô‡πÄ‡∏´‡∏ô‡∏µ‡∏¢‡∏ß
            if rel['source_id'] not in node_ids:
                nodes.append({"id": rel['source_id'], "label": rel['source'], "group": rel['source_labels'][0] if rel.get('source_labels') else 'Unknown'})
                node_ids.add(rel['source_id'])
            if rel['target_id'] not in node_ids:
                nodes.append({"id": rel['target_id'], "label": rel['target'], "group": rel['target_labels'][0] if rel.get('target_labels') else 'Unknown'})
                node_ids.add(rel['target_id'])
            edges.append({"from": rel['source_id'], "to": rel['target_id'], "label": rel['relationship'].replace("_", " ").lower(), "arrows": "to"})
        
        return {"nodes": nodes, "edges": edges}
    
    except Exception as e:
        print(f"‚ùå API Error on /api/graph/explore: {e}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"An error occurred while fetching graph data: {e}")

print("üåê ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏õ‡∏¥‡∏î‡∏õ‡∏£‡∏∞‡∏ï‡∏π‡∏°‡∏¥‡∏ï‡∏¥... ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå FastAPI...")

if __name__ == "__main__":
    uvicorn.run("main:app", host="127.0.0.1", port=8000, reload=True)